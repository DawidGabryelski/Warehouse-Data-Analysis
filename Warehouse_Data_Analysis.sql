with critical_items as (
	-- Identifying items that are both historically and currently problematic 
	-- and calculating the number of days the current stock covers the daily demand
	select
		w.item_id,
		w.category,
		w.stock_level,
		w.reorder_point,
		round(w.daily_demand, 0) as daily_demand, 
		round((w.stock_level / w.daily_demand), 0) as demand_coverage_days
	from warehouse w
	where
		-- Filter 1: Historical risk - items that experienced a stockout last month
		w.stockout_count_last_month > 0
		-- Filter 2: Current risk - stock is below the reorder threshold
		and w.stock_level < w.reorder_point
		-- Filter 3: Prevention of division by zero
		and w.daily_demand > 0
)
-- Aggregating the critical items data to gain strategic insights by category:
-- counting the number of high-risk items in each category and calculating
-- the average demand coverage (in days) for this high-risk subset.
select
	category,
	count(*) as critical_points, 
	round(avg(demand_coverage_days), 0) as avg_demand_coverage_days
from critical_items
group by 1

create view abc_xyz as
	with base_data as(
		-- Select core item data required for both ABC (value) and XYZ (volatility) classifications
		select
			item_id, 
			category,
			zone,
			total_orders_last_month, 
			unit_price,
			daily_demand,
			demand_std_dev
		from warehouse w
	),
	annual_value as(
		-- Calculate the total monetary value generated by each item (value = orders * price)
		select
			*,
			round((total_orders_last_month * unit_price), 0) as annual_value
			from base_data
	),
	ranked_value as(
		-- Rank items by their total value in descending order (highest value first)
		select 
			*,
			rank() over(order by annual_value desc) as rnk
		from annual_value
	),
	running_total_value as(
		-- Calculate the running (cumulative) total value based on the rank
		select 
			*,
			sum(annual_value) over(order by rnk) as running_total_value
		from ranked_value
	),
	cumulative_value_prc as(
		-- Calculate the cumulative percentage of the total value across all items
		select
			*,
			round(running_total_value * 100.0 / (select sum(annual_value) from annual_value), 3) as run_total_val_prc
		from running_total_value
	),
	abc_segregation as(
		-- Assign ABC classification based on cumulative value percentage (standard Pareto rules: 80/15/5)
		select
			*,
			case 
				when run_total_val_prc <= 80 then 'A'
				when run_total_val_prc > 80 and run_total_val_prc <= 95 then 'B'
				when run_total_val_prc > 95 then 'C'		
			end	as abc_segregation
		from cumulative_value_prc
	),
	demand_volatility as(
		-- Calculate the coefficient of variation (CoV) for XYZ classification
		-- CoV = demand_std_dev / daily_demand. nullif prevents division by zero.
		select
		    item_id,
		    round((demand_std_dev / nullif(daily_demand, 0)), 2) as demand_volatility
		from warehouse
	),
	xyz_segregation as(
		-- Assign XYZ classification based on the coefficient of variation (CoV)
		-- X: stable demand (CoV <= 0.5); Y: moderate variability (0.5 < CoV <= 1.5); Z: high variability (CoV > 1.5)
		select 
			*,
			case 
				when demand_volatility <= 0.5 then 'X'
				when demand_volatility > 0.5 and demand_volatility <= 1.5 then 'Y'
				when demand_volatility > 1.5 then 'Z'
			end as xyz_segregation
		from demand_volatility
	),
	abc_xyz_join as(
		-- Join the ABC and XYZ classifications back together based on item_id
		select 
			abc.item_id,
			abc.category,
			abc.zone,
			abc.total_orders_last_month,
			abc.unit_price,
			abc.annual_value as total_revenue,
			abc.daily_demand,
			abc.abc_segregation as abc_cl,
			xyz.xyz_segregation as xyz_cl
		from abc_segregation abc
		join xyz_segregation xyz on abc.item_id = xyz.item_id
	)
	select 
		item_id,
		category,
		zone,
		total_orders_last_month,
		unit_price,
		total_revenue,
		daily_demand,
		-- Final mapping of the 9 classification combinations (e.g., AX, BY, CZ)
		case 
			when abc_cl = 'A' and xyz_cl = 'X' then 'AX'
			when abc_cl = 'A' and xyz_cl = 'Y' then 'AY'
			when abc_cl = 'A' and xyz_cl = 'Z' then 'AZ'
			when abc_cl = 'B' and xyz_cl = 'X' then 'BX'
			when abc_cl = 'B' and xyz_cl = 'Y' then 'BY'
			when abc_cl = 'B' and xyz_cl = 'Z' then 'BZ'
			when abc_cl = 'C' and xyz_cl = 'X' then 'CX'
			when abc_cl = 'C' and xyz_cl = 'Y' then 'CY'
			when abc_cl = 'C' and xyz_cl = 'Z' then 'CZ'
		end	as abc_xyz
	from abc_xyz_join;

-- Analysis to find the operational bottleneck: compare picking time and layout efficiency 
-- between the most problematic (AZ) and least problematic (CX) groups
select
    ax.abc_xyz,
    w.zone,
    round(avg(w.picking_time_seconds), 0) as avg_pick_time,
    round(avg(w.layout_efficiency_score), 2) as avg_layout_efficiency
from warehouse w
join abc_xyz ax on w.item_id = ax.item_id
where ax.abc_xyz in('AZ', 'CX') -- focusing on high-risk (AZ) vs. low-risk (CX)
group by 1, 2;

-- analysis to confirm strategic alignment: check if high-value items (A) generate more value per second
-- by calculating value added per second of picking time (value / time)
select
    ax.abc_xyz,
    round(sum(ax.total_revenue) / sum(w.picking_time_seconds), 0) as value_per_second
from warehouse w
join abc_xyz ax on w.item_id = ax.item_id
group by 1;

with supplier_lead_gap as(
	-- Calculating the difference between supplier lead time and internal reorder frequency
	-- positive gap means lead time is longer than reorder frequency (risk of stockouts)
	select
	    item_id,
	    category,
	    lead_time_days,      
	    reorder_frequency_days, 
	    (lead_time_days - reorder_frequency_days) as lead_time_vs_reorder_gap
	from warehouse),
at_risk_skus_by_class as(
	-- Counting the number of high-risk items (where the gap is positive) grouped by ABC/XYZ classification
	select  
		ax.abc_xyz, 
		count(ora.item_id) as num_logistics_risk 
	from supplier_lead_gap ora 
	join abc_xyz ax on ax.item_id = ora.item_id 
	where ora.lead_time_vs_reorder_gap > 0 
	group by 1)
-- Assessing customer fulfillment performance and kpi score based on product classification
	
select
    ax.abc_xyz,
    round(avg(w.order_fulfillment_rate), 2) as avg_order_fill_rate, 
    round(avg(w.kpi_score), 2) as avg_op_performance 
from warehouse w
join abc_xyz ax on w.item_id = ax.item_id 
group by 1;

with capital_efficiency_metrics as( 
	-- Calculating the key financial metrics aggregated by product category
	select
	    category,
	    round(avg(turnover_ratio), 2) as avg_turnover_ratio,
	    round(avg(holding_cost_per_unit_day), 3) as avg_inventory_holding_cost, 
	    -- Capital burden index (CBI): (holding cost / turnover ratio) - measures the cost of holding inventory per sale unit
	    -- Higher index is worse, indicating less efficient capital use
	    round(avg(holding_cost_per_unit_day) / avg(turnover_ratio), 3) as capital_burden_index
	from warehouse
	group by 1)
-- Selecting all data and filters out categories with zero or negative turnover ratio
select 
	* 
from capital_efficiency_metrics 
where avg_turnover_ratio > 0;

with supplier_lead_gap as(
	-- Calculating the difference between supplier lead time and internal reorder frequency
	select
	    item_id,
	    (lead_time_days - reorder_frequency_days) as lead_time_vs_reorder_gap
	from warehouse)
-- Final SELECT to count and output the number of at-risk SKUs by ABC/XYZ class
select  
	ax.abc_xyz, 
	count(ora.item_id) as num_logistics_risk 
from supplier_lead_gap ora 
join abc_xyz ax on ax.item_id = ora.item_id 
where ora.lead_time_vs_reorder_gap > 0 
group by 1;







